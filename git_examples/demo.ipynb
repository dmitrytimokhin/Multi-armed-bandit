{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceBandits Contextual Bandits Demo\n",
    "Этот блокнот демонстрирует базовое использование SpaceBandits. Пакет в настоящее время находится в разработке. Установить с помощью:\n",
    "\n",
    "```\n",
    "pip install space_bandits\n",
    "```\n",
    "\n",
    "## Построить линейную модель\n",
    "Самая простая модель в пакетах сопоставляет контексты с ожидаемыми вознаграждениями с линейными коэффициентами. Используйте функцию конструктора модели; необходимо указать длину признака (количество признаков в строке) и количество доступных действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space_bandits import LinearBandits\n",
    "\n",
    "num_actions = 5 #five actions\n",
    "num_features = 10 #ten features\n",
    "\n",
    "model = LinearBandits(num_actions, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучите модель с помощью метода .update()\n",
    "Используйте прошлые примеры контекста, действия, вознаграждения для обучения модели. Контекст должен иметь указанное выше измерение; каждый пример обучения должен включать одно действие (индексированное с нуля) и одно связанное вознаграждение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example context vector: \n",
      " [0.85174531 0.14239978 0.01099373 0.90709505 0.67988471 0.6440062\n",
      " 0.21293169 0.09332591 0.6603089  0.78953261]\n",
      "example action chosen: \n",
      " 2\n",
      "example reward associated with: \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "context = np.random.random((10))\n",
    "print('пример вектора контекста: \\n', context)\n",
    "action = 2\n",
    "print('пример выбранного действия: \\n', action)\n",
    "reward = 5\n",
    "print('пример вознаграждения: \\n', reward)\n",
    "\n",
    "#здесь мы обновляем модель:\n",
    "model.update(context, action, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Принимайте решения с помощью метода .action()\n",
    "\n",
    "После обучения модели мы можем использовать метод .action() для сопоставления заданного контекста с действием с наивысшим ожидаемым вознаграждением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new example context vector: \n",
      " [0.0425226  0.43738244 0.07786224 0.25217616 0.91765093 0.19091702\n",
      " 0.92737656 0.29993496 0.45324536 0.08770382]\n",
      "model suggested action: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "new_context = np.random.random((10))\n",
    "print('новый пример вектора контекста: \\n', context)\n",
    "\n",
    "print('модель предложила действие: ')\n",
    "print(model.action(new_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ожидаемые значения\n",
    "Мы можем напрямую вывести ожидаемые значения модели для каждого действия, учитывая контекст, используя метод expected_values(). Неопределенность ожидаемых значений не принимается во внимание в этом вычислении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ожидаемые значения для примера контекста: \n",
      "[0.         0.         4.74007592 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('ожидаемые значения для примера контекста: ')\n",
    "print(model.expected_values(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Parameters\n",
    "### Memory Management\n",
    "The model keeps a record of all previous examples; this is useful for updating, but it's impractical in ongoing production scenarios. To limit the model's memory, specify the number of previous examples to \"remember\" using the memory_size argument.\n",
    "\n",
    "```python\n",
    "model = init_linear_model(num_actions, context_dim, memory_size=1000000)\n",
    "```\n",
    "\n",
    "The above specifies that the model only keep a running record of the last 1000000 examples.\n",
    "\n",
    "### Initial Exploration\n",
    "Thompson sampling gives us continuous, intelligent exploration throughout the model's lifetime. However, initial exploration can be very helpful for encouraging model convergence, especially with a cold start. Use the initial_pulls argument to force the model to explore before defaulting to Thompson sampling. The model will sequentially try each action initial_pulls number of times; this results in initial_pulls * n_actions exploratory actions.\n",
    "\n",
    "```python\n",
    "model = init_linear_model(num_actions, context_dim, initial_pulls=2)\n",
    "```\n",
    "\n",
    "The above will result in the model suggesting each action 2 times before using Thompson sampling to suggest actions.\n",
    "\n",
    "### Saving Your Model\n",
    "Each SpaceBandits model has a .save() method. Use it to save models for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_saved_model') #save to file my_saved_model\n",
    "\n",
    "from space_bandits import load_model\n",
    "\n",
    "model = load_model('my_saved_model') #load from same location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Model\n",
    "\n",
    "Linear models are powerful but inherently limited. The Neural-Linear Bayesian Contextual Bandits model, which was named and explored in the 2018 research paper [Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling](https://arxiv.org/pdf/1802.09127.pdf), uses a neural network to give the model a powerful way to map a feature vector to a latent representational feature space. These learned features are used in a standard linear model identical to the one used above.<br><br>\n",
    "SpaceBandits lets us deploy the same model with the API as above. In practice, designing the model is can be somewhat complicated; the neural network adds a huge number of hyperparameters. SpaceBandits uses the default parameters used in the research paper to give users a nice starting point; modifying them is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space_bandits import NeuralBandits\n",
    "\n",
    "model = NeuralBandits(num_actions, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update the model in the same way as before. To improve training efficiency, the neural network only trains after a pre-defined number of updates. The default neural network training frequency is every 50 updates (modify the training_freq_network argument to change this); each time this occurs, the network trains for 100 epochs at each training session by default (modify the training_epochs argument to change this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural_model-bnn for 100 steps...\n",
      "Training neural_model-bnn for 100 steps...\n"
     ]
    }
   ],
   "source": [
    "# here we update the model 100 times.\n",
    "\n",
    "for i in range(100):\n",
    "    context = np.random.random((10))\n",
    "    action = np.random.randint(0, 4)\n",
    "    reward = np.random.random() * 10\n",
    "    model.update(context, action, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the linear model, the neural model will record all examples by default; modify the memory_size parameter (default value -1, for inf) on the constructor function to manage memory and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Neural Model\n",
    "\n",
    "Neural models actually consist of two models: a neural network and a Bayesian linear regression model. To manage this for saving, SpaceBandits creates a .zip file that keeps your models together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_neural_model.pkl')\n",
    "\n",
    "#don't forget the .zip extension when restoring your neural model.\n",
    "model = load_model('my_neural_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Values\n",
    "We don't like black boxes. Model interpretation is critical for solid data science. Any SpaceBandits model will return its expected reward values for a given context using the .expected_values() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01993425, 5.70811732, 2.41866919, 5.86543991, 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.expected_values(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural models make use of a latent representation of the input features; this feature vector is called $z$ in the Google Brain research paper. You can retrieve the model's latent feature vector using the .get_representation() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1710,  0.0000,  0.0000,  1.8167,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000, 13.5386,  3.6377,  0.0000,  0.0000,  8.4940,  0.0000,\n",
       "         2.7854,  7.9246,  0.0000,  0.0000,  8.4467,  0.0000,  0.0000,  0.0000,\n",
       "         9.4823,  0.0000,  7.0178,  5.1963,  2.3382,  5.0501,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.4022,  0.0000, 11.3781,  0.0000,  0.0000,  0.0000,  0.3589,  0.0000,\n",
       "         6.1590,  0.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_representation(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 50-dimensional vector encodes the useful information in a context for our linear model to use. While it may not seem particularly useful at this time, remember: SpaceBandits is from the future, and we know this stuff turns out to be important ;)<br><br>\n",
    "By default, the neural network has one hidden layer with 50 nodes. Use a list of integers in the layer_sizes argument to the constructor to specify number of layers and nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluating bandit models in real-life situations is not easy. The only way to really tell if your model is doing well is to put it into production and compare its results to other decision-making policies. Simulations and toy problems where action/reward relationships are known are a great place to start. Unfortunately, public contextual bandits datasets are hard to come by!<br><br>\n",
    "For a look at some toy problems, check out the [toy problem notebook](toy_problem.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
